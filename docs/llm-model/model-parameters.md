# Model Parameters

Эти настройки помогают контролировать, как модель будет формировать ответы персонажа.

- Model — выберите подходящую модель для работы персонажа.
- Temperature — уровень креативности ответов. Рекомендуемое значение: 0.5–1.1. Чем выше, тем более разнообразны и нестандартны ответы.
- Top-P — ограничивает выбор слов самым вероятным набором, покрывающим вероятность P. Например, при P=0.9 модель выбирает слова, которые суммарно дают 90% вероятности.
- Top-K — ограничивает выбор K наиболее вероятными словами. Например, при K=50 модель учитывает только 50 самых вероятных слов.
- Total Context Tokens — максимальный размер контекста, который модель учитывает при генерации ответа.
- Max Response Tokens — ограничение длины ответа. Для английского примерно 100 токенов ≈ 70 слов.
- Presence Penalty — снижает вероятность повторения уже использованных слов. Чем выше значение, тем сильнее эффект.
- Frequency Penalty — штрафует за частое повторение одних и тех же слов. Высокое значение уменьшает повторяемость выражений

![](assets/image/llm-model/1.png#only-light){.on-glb data-gallery="only-light"}
![](assets/image/llm-model/1_dark.png#only-dark){.on-glb data-gallery="only-dark"}

!!! info

	Для персонажей с уникальным стилем речи можно увеличить Temperature, а для точных и лаконичных ответов — снизить.

	Для уменьшения повторов используйте Presence и Frequency Penalty в умеренных значениях.